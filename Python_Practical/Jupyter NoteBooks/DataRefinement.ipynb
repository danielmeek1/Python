{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d43ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7140ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9880f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/CometLanding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67ed91",
   "metadata": {},
   "source": [
    "# Data Refinement Justifications\n",
    "\n",
    "In order to refine the data, we first had to know the structure of the data. Therefore, we did research on the Twitter API through resources Twitter provides for developers. After this research process, we have identified the dataset structure and we have defined functions that would check whether the data we were given is in the specified structure. \n",
    "\n",
    "It's our view that any tweet data that doesn't follow the tweet structure can not be viewed as a valid tweet and it can't be trusted. Therefore, to achieve correctness in data analysis, we have removed the data that was inconsistent with the structure from our dataset. \n",
    "\n",
    "In this project, we focused on reproducibility so that our project would be able to analyze any tweet data no matter what the context is. Therefore, we completely avoided doing any kind of manual checking. All of the functions we have defined in data refinement work on tweet objects which are universal to any tweet data. \n",
    "\n",
    "Furthermore, it was also crucial for us to have a repetable code to make sure that we minimize unnecessary frictions and distractions during our development process. This also ensured we were able to avoid having bugs that are hard to debug in our code. Hence, we organized the functions according to what tweet object the function works on, and we have used commenting that explains how the function is supposed to work. \n",
    "\n",
    "Lastly, the structuring of our code alongside using very well known and robust frameworks such as pandas makes sure the code can be used in other settings with minimal change. We will talk more about why we structured our code in the way we did in data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b06764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function removes any duplicate data  '''\n",
    "def basicDataCleaning(df):\n",
    "    df = df.drop_duplicates(keep = 'first')\n",
    "    df = df.drop_duplicates(subset=['id_str'], keep='first')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fdcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function asserts that the user name follows the specified data format in the Twitter API'''\n",
    "''' Source:https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet'''\n",
    "''' Usernames that are longer than 15 Characters are not valid '''\n",
    "''' Usernames that contain non-alphanumeric characters are not valid with the exception of underscores '''\n",
    "''' Usernames containing the words Twitter or Admin are not valid  '''\n",
    "\n",
    "def validateUserName(df):\n",
    "    \n",
    "    df = df.drop(df[df['from_user'].str.len() > 15].index)  \n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'[a-zA-Z0-9_]', str(x)) == None)].index)\n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'Twitter', str(x), re.IGNORECASE) != None)].index)\n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'Admin', str(x), re.IGNORECASE) != None)].index)                 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272c83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function processes language data to achieve uniformity to ease data analysis'''\n",
    "''' Turns data such as 'en-gb' to 'en' only to achieve consistency'''\n",
    "''' Turns all data lower-case to achieve consistency'''\n",
    "\n",
    "def refineLanguageData(df):\n",
    "    df['user_lang'] = df['user_lang'].str.lower()\n",
    "    df['user_lang'] = df[\"user_lang\"].replace({'en-gb':'en'}, regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6353144",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function asserts that the tweet length is within the parameters set in Twitter API'''\n",
    "'''Although the maximum tweet length is 280 characters today\n",
    "tweets could contain maximum 140 characters before November 8th 2017 (our data is from 2014)'''\n",
    "'''Any tweet that is longer than 140 characters are removed'''\n",
    "def validateTweetLength(df):\n",
    "    \n",
    "    df = df.drop(df[df['text'].str.len() > 140].index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dca296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Function removes the data that do not follow twitter specifications for tweet replies'''\n",
    "'''If a tweet is a reply, in_reply_to_user_id_str and in_reply_to_status_id_str must be not null'''\n",
    "'''Source:https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet'''\n",
    "#https://thispointer.com/pandas-4-ways-to-check-if-a-dataframe-is-empty-in-python/#:~:text=Check%20if%20dataframe%20is%20empty%20using%20Dataframe.&text=If%20our%20dataframe%20is%20empty,is%200%20in%20this%20tuple.\n",
    "\n",
    "def validateReplyConsistency(df):\n",
    "    \n",
    "    for namedTuple in df.itertuples():\n",
    "        in_reply_to_user_id_str = namedTuple[8]\n",
    "        in_reply_to_status_id_str = namedTuple[11]\n",
    "\n",
    "        if math.isnan(in_reply_to_user_id_str) == True and math.isnan(in_reply_to_status_id_str) == False:\n",
    "            df = df.drop(namedTuple)    \n",
    "        elif math.isnan(in_reply_to_user_id_str) == True and math.isnan(in_reply_to_status_id_str) == False:\n",
    "            df = df.drop(namedTuple)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac76285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function creates new CSV file with the cleaned dataset to use in analysis ''' \n",
    "def createCleanedCSV(df):\n",
    "    df.to_csv(\"./data/CleanedCometLanding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c598bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function calls all of the functions to refine the dataset and save refined data into a seperate csv file'''\n",
    "def refineDataset(df):\n",
    "    df1 = basicDataCleaning(df)\n",
    "    df2 = validateUserName(df1)\n",
    "    df3 = refineLanguageData(df2)\n",
    "    df4 = validateTweetLength(df3)\n",
    "    df5 = validateReplyConsistency(df4)\n",
    "    df6 = validateReplyConsistency(df5)\n",
    "    createCleanedCSV(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2121a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "refineDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a269e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def main():\n",
    "\n",
    "    #pd.set_option('max_colwidth', 400)\n",
    "    #df = pd.read_csv('CometLanding.csv')\n",
    "    #refineDataset(df)\n",
    "    \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
