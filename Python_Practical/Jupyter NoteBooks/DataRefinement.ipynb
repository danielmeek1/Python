{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d43ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7140ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9880f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/CometLanding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79158027",
   "metadata": {},
   "source": [
    "# Data Refinement Justifications\n",
    "\n",
    "In order to refine the data, we first had to know the structure of the data. Therefore, we did research on the Twitter API through resources Twitter provides for developers. After this research process, we have identified the dataset structure and we have defined functions that would check whether the data we were given is in the specified structure. \n",
    "\n",
    "It's our view that any tweet data that doesn't follow the tweet structure can not be viewed as a valid tweet and it can't be trusted. Therefore, to achieve correctness in data analysis we have removed the data that was inconsistent with the structure from our dataset. \n",
    "\n",
    "In this project, we focused on reproducibility so that our project would be able to analyze any tweet data no matter what the context is. Therefore, we completely avoided doing any kind of manual checking. All of the functions we have defined in data refinement work on tweet objects which are universal to any tweet data. \n",
    "\n",
    "Furthermore, it was also crucial for us to have a repetable code to make sure that we minimize unnecessary frictions and distractions during our development process to avoid having bugs in our code. Hence, we organized the functions according to what tweet object the function works on. \n",
    "\n",
    "Lastly, this structuring of our code alongside using very well known and robust frameworks such as pandas makes sure the code can be used in other settings with minimal change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b06764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function removes any duplicate data  '''\n",
    "def basicDataCleaning(df):\n",
    "    df = df.drop_duplicates(keep = 'first')\n",
    "    df = df.drop_duplicates(subset=['id_str'], keep='first')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fdcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function asserts that the user name follows the specified data format in the Twitter API'''\n",
    "''' Source:https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet'''\n",
    "''' Usernames that are longer than 15 Characters are not valid '''\n",
    "''' Usernames that contain non-alphanumeric characters are not valid with the exception of underscores '''\n",
    "''' Usernames containing the words Twitter or Admin are not valid  '''\n",
    "\n",
    "def validateUserName(df):\n",
    "    \n",
    "    df = df.drop(df[df['from_user'].str.len() > 15].index)  \n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'[a-zA-Z0-9_]', str(x)) == None)].index)\n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'Twitter', str(x), re.IGNORECASE) != None)].index)\n",
    "    df = df.drop(df[df['from_user'].apply(lambda x: re.search(r'Admin', str(x), re.IGNORECASE) != None)].index)                 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994b364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateEssentialData(df):\n",
    "  \n",
    "    for namedTuple in df.itertuples():\n",
    "        tweetID = namedTuple[1]\n",
    "        userName = namedTuple[2]\n",
    "        tweet = namedTuple[3]\n",
    "        userID = namedTuple[10]\n",
    "        \n",
    "        if pd.isnull(tweetID) == False:\n",
    "            df = df.drop(namedTuple , axis=1)     \n",
    "        elif pd.isnull(userName) == False:\n",
    "            df = df.drop(namedTuple, axis=1)\n",
    "            \n",
    "        elif pd.isnull(tweet) == False:\n",
    "            df = df.drop(namedTuple , axis=1)\n",
    "            \n",
    "        elif pd.isnull(userID) == False:\n",
    "            df = df.drop(namedTuple , axis=1) \n",
    "    \n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8298b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[(0, 5.40930409279008e+17, \\'hihihihihiamika0078788556\\', \\'RT @VersaTechnology: Congratulations @Philae2014 #Philae touches down on the surface of a comet!! Follow her on twitter: http://t.co/6SoGeZâ€¦\\', \\'Fri Dec 05 18:07:14 +0000 2014\\', \\'05/12/2014 18:07\\', nan, \\'EN-gb\\', nan, nan, 1297570116.0, nan, \\'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>\\', \\'http://pbs.twimg.com/profile_images/3555068293/27b2eab08ef5207ec11309e99c40a9ed_normal.jpeg\\', 425.0, 113.0, \\'http://twitter.com/amika0078788556/statuses/540930409279008768\\', \\'{\"hashtags\":[{\"text\":\"Philae\",\"indices\":[49,56]},{\"text\":\"CometLanding\",\"indices\":[139,140]}],\"symbols\":[],\"user_mentions\":[{\"screen_name\":\"VersaTechnology\",\"name\":\"Versa Technology\",\"id\":30264992,\"id_str\":\"30264992\",\"indices\":[3,19]},{\"screen_name\":\"Philae2014\",\"name\":\"Philae Lander\",\"id\":208442526,\"id_str\":\"208442526\",\"indices\":[37,48]}],\"urls\":[{\"url\":\"http://t.co/6SoGeZTS9N\",\"expanded_url\":\"http://cnn.it/1qDQu0s\",\"display_url\":\"cnn.it/1qDQu0s\",\"indices\":[139,140]}]}\\')] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvalidateEssentialData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mvalidateEssentialData\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m userID \u001b[38;5;241m=\u001b[39m namedTuple[\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(tweetID) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamedTuple\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m     \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(userName) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(namedTuple, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:4948\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4802\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4809\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4810\u001b[0m ):\n\u001b[1;32m   4811\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4812\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4813\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4946\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4950\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4954\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:4279\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4279\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:4323\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4321\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4323\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4324\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4326\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[(0, 5.40930409279008e+17, \\'hihihihihiamika0078788556\\', \\'RT @VersaTechnology: Congratulations @Philae2014 #Philae touches down on the surface of a comet!! Follow her on twitter: http://t.co/6SoGeZâ€¦\\', \\'Fri Dec 05 18:07:14 +0000 2014\\', \\'05/12/2014 18:07\\', nan, \\'EN-gb\\', nan, nan, 1297570116.0, nan, \\'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>\\', \\'http://pbs.twimg.com/profile_images/3555068293/27b2eab08ef5207ec11309e99c40a9ed_normal.jpeg\\', 425.0, 113.0, \\'http://twitter.com/amika0078788556/statuses/540930409279008768\\', \\'{\"hashtags\":[{\"text\":\"Philae\",\"indices\":[49,56]},{\"text\":\"CometLanding\",\"indices\":[139,140]}],\"symbols\":[],\"user_mentions\":[{\"screen_name\":\"VersaTechnology\",\"name\":\"Versa Technology\",\"id\":30264992,\"id_str\":\"30264992\",\"indices\":[3,19]},{\"screen_name\":\"Philae2014\",\"name\":\"Philae Lander\",\"id\":208442526,\"id_str\":\"208442526\",\"indices\":[37,48]}],\"urls\":[{\"url\":\"http://t.co/6SoGeZTS9N\",\"expanded_url\":\"http://cnn.it/1qDQu0s\",\"display_url\":\"cnn.it/1qDQu0s\",\"indices\":[139,140]}]}\\')] not found in axis'"
     ]
    }
   ],
   "source": [
    "validateEssentialData(df)\n",
    "\n",
    "    \n",
    "    #for index, row in df.iterrows():\n",
    "        #if(row['id_str'])validateEssentialData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function processes language data to achieve uniformity to ease data analysis'''\n",
    "''' Turns data such as 'en-gb' to 'en' only to achieve consistency'''\n",
    "''' Turns all data lower-case to achieve consistency'''\n",
    "\n",
    "def refineLanguageData(df):\n",
    "    df['user_lang'] = df['user_lang'].str.lower()\n",
    "    df['user_lang'] = df[\"user_lang\"].replace({'en-gb':'en'}, regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6353144",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function asserts that the tweet length is within the parameters set in Twitter API'''\n",
    "'''Although the maximum tweet length is 280 characters today\n",
    "tweets could contain maximum 140 characters before November 8th 2017 (our data is from 2014)'''\n",
    "'''Any tweet that is longer than 140 characters are removed'''\n",
    "def validateTweetLength(df):\n",
    "    \n",
    "    df = df.drop(df[df['text'].str.len() > 140].index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Function removes the data that do not follow twitter specifications for tweet replies'''\n",
    "'''If a tweet is a reply, in_reply_to_user_id_str and in_reply_to_status_id_str must be not null'''\n",
    "'''Source:https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet'''\n",
    "#https://thispointer.com/pandas-4-ways-to-check-if-a-dataframe-is-empty-in-python/#:~:text=Check%20if%20dataframe%20is%20empty%20using%20Dataframe.&text=If%20our%20dataframe%20is%20empty,is%200%20in%20this%20tuple.\n",
    "\n",
    "def validateReplyConsistency(df):\n",
    "    \n",
    "    for namedTuple in df.itertuples():\n",
    "        in_reply_to_user_id_str = namedTuple[8]\n",
    "        in_reply_to_status_id_str = namedTuple[11]\n",
    "\n",
    "        if math.isnan(in_reply_to_user_id_str) == True and math.isnan(in_reply_to_status_id_str) == False:\n",
    "            df = df.drop(namedTuple)    \n",
    "        elif math.isnan(in_reply_to_user_id_str) == True and math.isnan(in_reply_to_status_id_str) == False:\n",
    "            df = df.drop(namedTuple)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function creates new CSV file with the cleaned dataset to use in analysis ''' \n",
    "def createCleanedCSV(df):\n",
    "    df.to_csv(\"./data/CleanedCometLanding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5077f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function calls all of the functions to refine the dataset and save refined data into a seperate csv file'''\n",
    "def refineDataset(df):\n",
    "    df1 = basicDataCleaning(df)\n",
    "    df2 = validateUserName(df1)\n",
    "    df3 = refineLanguageData(df2)\n",
    "    df4 = validateTweetLength(df3)\n",
    "    df5 = validateReplyConsistency(df4)\n",
    "    df6 = validateReplyConsistency(df5)\n",
    "    createCleanedCSV(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "refineDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a269e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    #77319 rows × 17 columns original data\n",
    "    df = pd.read_csv('CometLanding.csv')\n",
    "    refineDataset(df)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
